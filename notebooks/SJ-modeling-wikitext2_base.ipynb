{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-text-data\" data-toc-modified-id=\"Load-text-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load text data</a></span></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Model</a></span></li><li><span><a href=\"#Train\" data-toc-modified-id=\"Train-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Train</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T19:29:57.671166Z",
     "start_time": "2020-06-24T19:29:57.651266Z"
    }
   },
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T22:38:00.437247Z",
     "start_time": "2020-06-24T22:38:00.431496Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from io import open\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T19:29:58.675233Z",
     "start_time": "2020-06-24T19:29:58.672139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T00:29:01.224076Z",
     "start_time": "2020-06-25T00:29:01.176779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5e680228b0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T19:30:03.028261Z",
     "start_time": "2020-06-24T19:30:03.023151Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dictionary(object):\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = []\n",
    "        \n",
    "    def add_word(self, word):\n",
    "        \"\"\"\n",
    "        Add word to 'self.idx2word' and 'self.word2idx'.\n",
    "        \"\"\"\n",
    "        if word not in self.word2idx:\n",
    "            self.idx2word.append(word)\n",
    "            self.word2idx[word] = len(self.idx2word) - 1 # starts from 0\n",
    "        return self.word2idx[word]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T19:30:05.627540Z",
     "start_time": "2020-06-24T19:30:05.620440Z"
    }
   },
   "outputs": [],
   "source": [
    "class Corpus(object):\n",
    "    def __init__(self, path):\n",
    "        self.dictionary = Dictionary()\n",
    "        self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
    "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
    "        self.test = self.tokenize(os.path.join(path, 'test.txt'))\n",
    "        \n",
    "    def tokenize(self, path):\n",
    "        \"\"\"\n",
    "        Tokenize a text file and add tokens to the dictionary.\n",
    "        \"\"\"\n",
    "        assert os.path.exists(path)\n",
    "        \n",
    "        with open(path, 'r', encoding=\"utf8\") as f:\n",
    "            idx_all = []\n",
    "            for line in f:\n",
    "                words = line.split() + ['<eos>']\n",
    "                idx_line = []\n",
    "                for word in words:\n",
    "                    self.dictionary.add_word(word)\n",
    "                    idx_line.append(self.dictionary.word2idx[word])\n",
    "                idx_all.append(torch.tensor(idx_line).type(torch.int64))\n",
    "            ids = torch.cat(idx_all)               \n",
    "        return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T19:30:08.956575Z",
     "start_time": "2020-06-24T19:30:07.355751Z"
    }
   },
   "outputs": [],
   "source": [
    "model_data_filepath = 'data/'\n",
    "\n",
    "corpus = Corpus(model_data_filepath + 'wikitext-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T19:30:08.961614Z",
     "start_time": "2020-06-24T19:30:08.958555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.dictionary.word2idx['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T21:32:49.466389Z",
     "start_time": "2020-06-24T21:32:49.461912Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_batch(data, n_seq):\n",
    "    \"\"\"\n",
    "    Trim data and cleanly divide data into n_seq chunks.\n",
    "    \"\"\"\n",
    "    nbatch = data.size(0) // n_seq\n",
    "    \n",
    "    # Trim off remainders.\n",
    "    data = data.narrow(0, 0, nbatch * n_seq)\n",
    "    \n",
    "    # Evenly divide the data across the n_seq batches.\n",
    "    # Shape : ([bptt, n_seq])\n",
    "    return data.view(n_seq, -1).t().contiguous().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_batch(source, i):\n",
    "#     \"\"\"\n",
    "#     Subdivides the source into chunks of length bptt.\n",
    "#     The chunks are along dimension 0 (length of each row is n_seq).\n",
    "#     \"\"\"\n",
    "#     seq_len = min(bptt, len(source)-1-i)\n",
    "#     data = source[i:i+seq_len]\n",
    "#     target = source[i+1:i+1+seq_len].view(-1)\n",
    "#     return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T22:47:26.866671Z",
     "start_time": "2020-06-24T22:47:26.862304Z"
    }
   },
   "outputs": [],
   "source": [
    "# class wikiDataset(Dataset):\n",
    "#     def __init__(self, data, n_seq):\n",
    "#         self.data = data\n",
    "#         self.n_seq = n_seq\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         data = self.data[idx]\n",
    "#         return make_batch(data, self.n_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T22:47:38.734455Z",
     "start_time": "2020-06-24T22:47:38.731701Z"
    }
   },
   "outputs": [],
   "source": [
    "# wiki_train = wikiDataset(corpus.train, n_seq=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T22:49:17.763387Z",
     "start_time": "2020-06-24T22:49:17.719307Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(wiki_train, batch_size=35, shuffle=False)\n",
    "# next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T00:29:44.439483Z",
     "start_time": "2020-06-25T00:29:44.436710Z"
    }
   },
   "outputs": [],
   "source": [
    "n_seq = 20\n",
    "eval_n_seq = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T00:29:54.600907Z",
     "start_time": "2020-06-25T00:29:54.536224Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = make_batch(corpus.train, n_seq)\n",
    "val_data = make_batch(corpus.valid, eval_n_seq)\n",
    "test_data = make_batch(corpus.test, eval_n_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T00:29:54.986636Z",
     "start_time": "2020-06-25T00:29:54.977828Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,   284, 15178,  ...,  1352,  1335,    16],\n",
       "        [    1,   357,    43,  ...,    46,    43,  2015],\n",
       "        [    2,  1496,  7369,  ...,   380,    27, 33001],\n",
       "        ...,\n",
       "        [  357,   415,   173,  ...,   212,    78,  1575],\n",
       "        [ 2520,     9,  3890,  ...,   208,    27,   808],\n",
       "        [   33,    35,    19,  ...,  8832,  6091,   209]], device='cuda:0')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T21:33:48.889960Z",
     "start_time": "2020-06-24T21:33:48.878459Z"
    }
   },
   "outputs": [],
   "source": [
    "class NWPMModel(nn.Module):\n",
    "    def __init__(self, ntoken, nemb, nhid, nlayers, dropout=0.5, tie_weights=False):\n",
    "        super().__init__()\n",
    "        self.ntoken = ntoken\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.encoder = nn.Embedding(ntoken, nemb)\n",
    "        self.rnn = nn.GRU(nemb, nhid, nlayers, dropout=dropout)\n",
    "        self.decoder = nn.Linear(nhid, ntoken)\n",
    "        \n",
    "        if tie_weights:\n",
    "            if nhid != nemb:\n",
    "                raise ValueError('When using the tied flag, nhid must be equal to nemb')\n",
    "            self.decoder.weight = self.encoder.weight\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "        self.nhid = nhid\n",
    "        self.nlayers = nlayers\n",
    "        \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        emb = self.drop(self.encoder(input))\n",
    "        output, hidden = self.rnn(emb, hidden)\n",
    "        output = self.drop(output)\n",
    "        decoded = self.decoder(output)\n",
    "        decoded = decoded.view(-1, self.ntoken)\n",
    "        return F.log_softmax(decoded, dim=1), hidden\n",
    "    \n",
    "    def init_hidden(self, n_seq):\n",
    "        weight = next(self.parameters())\n",
    "        return weight.new_zeros(self.nlayers, n_seq, self.nhid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T00:30:21.205896Z",
     "start_time": "2020-06-25T00:30:21.201318Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "ntokens = len(corpus.dictionary)\n",
    "bptt = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T00:30:21.852745Z",
     "start_time": "2020-06-25T00:30:21.654082Z"
    }
   },
   "outputs": [],
   "source": [
    "model = NWPMModel(\n",
    "    ntoken = ntokens,\n",
    "    nemb = 650,\n",
    "    nhid = 650,\n",
    "    nlayers=2,\n",
    "    dropout=0.2,\n",
    "    tie_weights=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T00:30:41.708192Z",
     "start_time": "2020-06-25T00:30:41.697211Z"
    }
   },
   "outputs": [],
   "source": [
    "def repackage_hidden(h):\n",
    "    \"\"\"\n",
    "    Wraps hidden states in new Tensors, to detach them from their history.\n",
    "    \"\"\"\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T00:30:41.995110Z",
     "start_time": "2020-06-25T00:30:41.987986Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_batch(source, i):\n",
    "    \"\"\"\n",
    "    Subdivides the source into chunks of length bptt.\n",
    "    The chunks are along dimension 0 (length of each row is n_seq).\n",
    "    \"\"\"\n",
    "    seq_len = min(bptt, len(source)-1-i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].view(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T00:30:42.392900Z",
     "start_time": "2020-06-25T00:30:42.370662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    0,   284, 15178,   280,   348,   128,   289,  9493,    16,     1,\n",
       "             13,     0,  2701,  1227,  1563,  4044,   115,  1352,  1335,    16],\n",
       "         [    1,   357,    43,  2977,   530, 23080,    13,    78,    17,     0,\n",
       "           4312,     0,   151,    22, 18215,    17,    17,    46,    43,  2015],\n",
       "         [    2,  1496,  7369,   115,  4782,    37, 22196,   252, 26998,     0,\n",
       "          28680,     1,   496,  2193,  1037,     9,  4072,   380,    27, 33001],\n",
       "         [    3,   449,   310,     9,    13,  8034,  3107,   639,    13, 27958,\n",
       "            638,     1,   168,    17,    43,  2786,    15,   160,   152,  3072],\n",
       "         [    4,  5181, 15182, 18712,   877,    16,   423,    22,   562,  1575,\n",
       "            496,     1,   209,  1056,    17,    39,   317, 19914,   128,   348],\n",
       "         [    1,    13,    15,    22, 17314,   357,  1517,   209,  2156,   348,\n",
       "            131,  2196,   146, 16561,   188, 31575,   348,    54,    52,   630],\n",
       "         [    0,    17,   652, 17400,   115,  3220,    59,    61,    13,   530,\n",
       "          15801,  1110,    22,  3168,   189,    15,    99,  8992,    15,   529],\n",
       "         [    0,  1207, 15183, 18712, 13108,  2004,   271,  1100,    37,    17,\n",
       "             61,    72,  1218,    52,    48,  2853,   530,    13,    61,   496],\n",
       "         [    5,  1870,    13,    93,    37,    13,    13,    16,  2751,  1760,\n",
       "             17,    37,    17,    22, 27572,    17,  5969,  4683, 32643,   530],\n",
       "         [    6,    43,    46,  1775,  4589, 23079,   162,  6659, 26999,    13,\n",
       "           6594,  7781,  4176,  2021,     8, 31575,    22,    46,  3241,  5234],\n",
       "         [    2,  1809,  1104,  1908,  2550, 18202, 22196,  4318,   321,  8033,\n",
       "             61,     1,    39,    39, 20503,   131,  7107,    23,  4730,  1857],\n",
       "         [    7,    13,    17,    15,    15,    13,   128,    61,    78,    13,\n",
       "             39,     1,   423,    54,  1115, 14584,   284,    46,    30,   440],\n",
       "         [    8, 10314,  3803,    83,     0,    43, 22179,    15, 23659,   310,\n",
       "             27,     1,    22,    33,    15,    43,   214,   380,  2054,    83],\n",
       "         [    9,   144,  3522,  2839,     0,    86,   131,     9,   221,  4201,\n",
       "           7615,     0,  3243,    80,  1923,  1129,   225,   119,   704, 12901],\n",
       "         [    3,    27,    16,   740,     1,    15, 13574,   131,   452,  1828,\n",
       "           3840,     0,  2931, 30616,  7810,   651,   119,    17,    15,    26],\n",
       "         [   10,  1426, 10525,  9989,     1, 18202,    93,  9629,    13,    17,\n",
       "             15, 14802,   826,    15,  5102,    16, 13102,  5048,     0,    27],\n",
       "         [   11,    30,  3773,   131, 11071,   131,    47,    35,   329,  4644,\n",
       "              0,  5594,  6308,   652,    93,    17,  2137,    16,     0,  6091],\n",
       "         [    8,  3022,    13,  2585,     1,    17,   271,    27,   707,    16,\n",
       "              0,   944,    17,    17,   361,  9170,    15,   225,     1,    16],\n",
       "         [   12,   910,    37,  1179,     1,    59,    39,  6670,   479, 27977,\n",
       "              1, 29432,    61,    59,  7935,    35,  5883, 27949,     1,    56],\n",
       "         [   13,  4781,    43,   998,     0,   578,    27,    43,  2576,     9,\n",
       "              1,  3409,   993,  3102,   119,    17,    13,    43, 29289,   496],\n",
       "         [   14,    15, 15184,    43,     0,  2004,  2923,    17,   115,    13,\n",
       "              1,    43,    61,  7359, 25670,    52,    17,    17,  7957,  3072],\n",
       "         [   15,    83,    46,    10,  6462,    22,    13,  8278,  1009,  5980,\n",
       "              9,  4848,    37,    80, 31219, 16703, 17570, 24897,     1,   348],\n",
       "         [    2, 10539,   131,  7428,   128,  5935,    37,    37,    43,    16,\n",
       "             93,    13,    61,    17, 28537,  4075,   300, 11319,     1,   186],\n",
       "         [   16, 10540,   677,  1179,  5158,    17,    17, 12376,    17, 20166,\n",
       "             83,  6385,   946,  3842,   128,    13, 18997,    37,     0,    13],\n",
       "         [   17,  2191,    15,  1326, 12169,  2015, 24277,  6714,   289,    37,\n",
       "          19900,    22,    61,  1237,   578,  1754,    37, 30532,     0,   119],\n",
       "         [   18,    17,    83,  3890,   257,    43,   664,  7121,    15,    17,\n",
       "              1,  5935,  5774, 29681, 14840,    17,  3122,   278,     0,    54],\n",
       "         [    7,   669,  1723,    19,    16,  1908,  1324,  8502,   135, 11528,\n",
       "              1,  5980,    15,    13,    13,     9,   227,   722,     1,  1022],\n",
       "         [   19,   831,  1109,   564,    17,  1193,    22,    15,    26,    10,\n",
       "              1,   128, 12890,    17,    37,    37,    17,    27,     1, 12672],\n",
       "         [   13, 10518, 15185,    13,  5158,    15, 21955,  7402,   253,  1984,\n",
       "              0,  3409,   128,  1056,   361,     9,   460,    47,     1,    37],\n",
       "         [   20,    93,  3033,   423,    16,     0,    17,   792,    43, 27329,\n",
       "              0,    13,  9824, 16561,  4336, 30155,    35,    16,  4724,    54],\n",
       "         [   21,   828, 10525,    22,   568,    83,  1665,    13,   159,    19,\n",
       "            123, 12890,  2057,   131,  4364,    13,    61,    17,  1839, 28100],\n",
       "         [   22,  1721,    43,  1721,  5764,   278,  1372,  5788,     9,    15,\n",
       "           7998,   766,     8,  6870,   119,    46,  4500,  4235,  1084,  2143],\n",
       "         [   23,    13,  6936,    43,    13,  3822,    15,   899,    43,   652,\n",
       "           3746,   151,    61, 10421,    17,   131, 13656,    16,     1,    13],\n",
       "         [    2,  3334,   440,    10,   766,  8034,    83,    78,  2183,     9,\n",
       "             16,   152,  1344,  1839,  1134,   808,    61,    17,     1,   162],\n",
       "         [    3,    13,    35,  4144, 16388,   131,  1665,  8180,  5151,    13,\n",
       "             17,    15,  8877,  2376,  1520,   538,    13, 11319,     1,  8276]],\n",
       "        device='cuda:0'),\n",
       " tensor([    1,   357,    43,  2977,   530, 23080,    13,    78,    17,     0,\n",
       "          4312,     0,   151,    22, 18215,    17,    17,    46,    43,  2015,\n",
       "             2,  1496,  7369,   115,  4782,    37, 22196,   252, 26998,     0,\n",
       "         28680,     1,   496,  2193,  1037,     9,  4072,   380,    27, 33001,\n",
       "             3,   449,   310,     9,    13,  8034,  3107,   639,    13, 27958,\n",
       "           638,     1,   168,    17,    43,  2786,    15,   160,   152,  3072,\n",
       "             4,  5181, 15182, 18712,   877,    16,   423,    22,   562,  1575,\n",
       "           496,     1,   209,  1056,    17,    39,   317, 19914,   128,   348,\n",
       "             1,    13,    15,    22, 17314,   357,  1517,   209,  2156,   348,\n",
       "           131,  2196,   146, 16561,   188, 31575,   348,    54,    52,   630,\n",
       "             0,    17,   652, 17400,   115,  3220,    59,    61,    13,   530,\n",
       "         15801,  1110,    22,  3168,   189,    15,    99,  8992,    15,   529,\n",
       "             0,  1207, 15183, 18712, 13108,  2004,   271,  1100,    37,    17,\n",
       "            61,    72,  1218,    52,    48,  2853,   530,    13,    61,   496,\n",
       "             5,  1870,    13,    93,    37,    13,    13,    16,  2751,  1760,\n",
       "            17,    37,    17,    22, 27572,    17,  5969,  4683, 32643,   530,\n",
       "             6,    43,    46,  1775,  4589, 23079,   162,  6659, 26999,    13,\n",
       "          6594,  7781,  4176,  2021,     8, 31575,    22,    46,  3241,  5234,\n",
       "             2,  1809,  1104,  1908,  2550, 18202, 22196,  4318,   321,  8033,\n",
       "            61,     1,    39,    39, 20503,   131,  7107,    23,  4730,  1857,\n",
       "             7,    13,    17,    15,    15,    13,   128,    61,    78,    13,\n",
       "            39,     1,   423,    54,  1115, 14584,   284,    46,    30,   440,\n",
       "             8, 10314,  3803,    83,     0,    43, 22179,    15, 23659,   310,\n",
       "            27,     1,    22,    33,    15,    43,   214,   380,  2054,    83,\n",
       "             9,   144,  3522,  2839,     0,    86,   131,     9,   221,  4201,\n",
       "          7615,     0,  3243,    80,  1923,  1129,   225,   119,   704, 12901,\n",
       "             3,    27,    16,   740,     1,    15, 13574,   131,   452,  1828,\n",
       "          3840,     0,  2931, 30616,  7810,   651,   119,    17,    15,    26,\n",
       "            10,  1426, 10525,  9989,     1, 18202,    93,  9629,    13,    17,\n",
       "            15, 14802,   826,    15,  5102,    16, 13102,  5048,     0,    27,\n",
       "            11,    30,  3773,   131, 11071,   131,    47,    35,   329,  4644,\n",
       "             0,  5594,  6308,   652,    93,    17,  2137,    16,     0,  6091,\n",
       "             8,  3022,    13,  2585,     1,    17,   271,    27,   707,    16,\n",
       "             0,   944,    17,    17,   361,  9170,    15,   225,     1,    16,\n",
       "            12,   910,    37,  1179,     1,    59,    39,  6670,   479, 27977,\n",
       "             1, 29432,    61,    59,  7935,    35,  5883, 27949,     1,    56,\n",
       "            13,  4781,    43,   998,     0,   578,    27,    43,  2576,     9,\n",
       "             1,  3409,   993,  3102,   119,    17,    13,    43, 29289,   496,\n",
       "            14,    15, 15184,    43,     0,  2004,  2923,    17,   115,    13,\n",
       "             1,    43,    61,  7359, 25670,    52,    17,    17,  7957,  3072,\n",
       "            15,    83,    46,    10,  6462,    22,    13,  8278,  1009,  5980,\n",
       "             9,  4848,    37,    80, 31219, 16703, 17570, 24897,     1,   348,\n",
       "             2, 10539,   131,  7428,   128,  5935,    37,    37,    43,    16,\n",
       "            93,    13,    61,    17, 28537,  4075,   300, 11319,     1,   186,\n",
       "            16, 10540,   677,  1179,  5158,    17,    17, 12376,    17, 20166,\n",
       "            83,  6385,   946,  3842,   128,    13, 18997,    37,     0,    13,\n",
       "            17,  2191,    15,  1326, 12169,  2015, 24277,  6714,   289,    37,\n",
       "         19900,    22,    61,  1237,   578,  1754,    37, 30532,     0,   119,\n",
       "            18,    17,    83,  3890,   257,    43,   664,  7121,    15,    17,\n",
       "             1,  5935,  5774, 29681, 14840,    17,  3122,   278,     0,    54,\n",
       "             7,   669,  1723,    19,    16,  1908,  1324,  8502,   135, 11528,\n",
       "             1,  5980,    15,    13,    13,     9,   227,   722,     1,  1022,\n",
       "            19,   831,  1109,   564,    17,  1193,    22,    15,    26,    10,\n",
       "             1,   128, 12890,    17,    37,    37,    17,    27,     1, 12672,\n",
       "            13, 10518, 15185,    13,  5158,    15, 21955,  7402,   253,  1984,\n",
       "             0,  3409,   128,  1056,   361,     9,   460,    47,     1,    37,\n",
       "            20,    93,  3033,   423,    16,     0,    17,   792,    43, 27329,\n",
       "             0,    13,  9824, 16561,  4336, 30155,    35,    16,  4724,    54,\n",
       "            21,   828, 10525,    22,   568,    83,  1665,    13,   159,    19,\n",
       "           123, 12890,  2057,   131,  4364,    13,    61,    17,  1839, 28100,\n",
       "            22,  1721,    43,  1721,  5764,   278,  1372,  5788,     9,    15,\n",
       "          7998,   766,     8,  6870,   119,    46,  4500,  4235,  1084,  2143,\n",
       "            23,    13,  6936,    43,    13,  3822,    15,   899,    43,   652,\n",
       "          3746,   151,    61, 10421,    17,   131, 13656,    16,     1,    13,\n",
       "             2,  3334,   440,    10,   766,  8034,    83,    78,  2183,     9,\n",
       "            16,   152,  1344,  1839,  1134,   808,    61,    17,     1,   162,\n",
       "             3,    13,    35,  4144, 16388,   131,  1665,  8180,  5151,    13,\n",
       "            17,    15,  8877,  2376,  1520,   538,    13, 11319,     1,  8276,\n",
       "             4,  1828,  1756,  1179,    37,   826,  4137,    93,    16,    17,\n",
       "           545,   697,  4453,    15,  8615,    43,  9254,    15,     0,  2313],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch(train_data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T00:32:33.507553Z",
     "start_time": "2020-06-25T00:32:33.497947Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(dataset, ntokens=len(corpus.dictionary), bptt=bptt):\n",
    "    model.eval() # disables dropout\n",
    "    sum_loss = 0\n",
    "    hidden = model.init_hidden(eval_n_seq)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, dataset.size(0)-1, bptt):\n",
    "            X, y = get_batch(dataset, i)\n",
    "            y_hat, hidden = model(X, hidden)\n",
    "            hidden = repackage_hidden(hidden)\n",
    "            sum_loss += len(X) * criterion(y_hat, y).item()\n",
    "    return sum_loss / (len(dataset)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T00:37:23.189077Z",
     "start_time": "2020-06-25T00:37:23.182449Z"
    }
   },
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lt=0.1,\n",
    "#                                                 steps_per_epoch=bptt, epochs=20)\n",
    "\n",
    "lr = 20\n",
    "epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T00:36:51.551917Z",
     "start_time": "2020-06-25T00:36:51.538461Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epochs(ntokens=len(corpus.dictionary), n_seq=n_seq, epochs=20, log_interval=200, lr=lr):\n",
    "    \"\"\"\n",
    "    Train for epochs.\n",
    "    \"\"\"\n",
    "    best_val_loss = None\n",
    "    for epoch in range(1, epochs+1):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        sum_loss = 0.\n",
    "        start_time = time.time()\n",
    "        hidden = model.init_hidden(n_seq)\n",
    "\n",
    "        for batch, i in enumerate(range(0, train_data.size(0)-1, bptt)):\n",
    "            X, y = get_batch(train_data, i)\n",
    "            \n",
    "            # Starting each batch, we detach the hidden state from how it was previously produced.\n",
    "            # If we didn't, the model would try backpropagating all the way to start of the dataset.\n",
    "            model.zero_grad()\n",
    "            hidden = repackage_hidden(hidden)\n",
    "            y_hat, hidden = model(X, hidden)\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "\n",
    "            # 'clip_grad_norm' helps prevent the exploding gradient problem in RNNs/LSTMs.\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n",
    "            for p in model.parameters():\n",
    "                p.data.add_(-lr, p.grad)\n",
    "\n",
    "            sum_loss += loss.item()\n",
    "\n",
    "            if batch % log_interval == 0 and batch > 0:\n",
    "                cur_loss = sum_loss / log_interval\n",
    "                elapsed = time.time() - start_time\n",
    "                print(f'| {epoch=:3d} | {batch:5d}/{len(train_data)//bptt} batches |  {lr=:2.2f}  |  '\n",
    "                f'{elapsed/log_interval :5.2f} s/batch | loss {cur_loss:5.2f} | ppl {math.exp(cur_loss):8.2f}')\n",
    "                sum_loss = 0\n",
    "                start_time = time.time()\n",
    "        \n",
    "        val_loss = evaluate(val_data)\n",
    "        print('-'*89)\n",
    "        print(f'| end of {epoch=:3d} | time: {time.time()-epoch_start_time:5.2f}s | {val_loss=:5.2f} | '\n",
    "              f'valid ppl {math.exp(val_loss):8.2f}')\n",
    "        print('-' * 89)\n",
    "        \n",
    "        # Save the model if the validation loss is the best we've seen so far.\n",
    "        if not best_val_loss or val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            model.save('model.pth')\n",
    "        else:\n",
    "            # Anneal the learning rate if no improvement has been seen in the validation dataset.\n",
    "            lr /= 4.0\n",
    "    os.rename('model.pth', f'model_val_loss_{val_loss:.2f}_val_ppl_{math.exp(val_loss):.2f}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-25T00:51:14.550195Z",
     "start_time": "2020-06-25T00:37:24.293712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch=  1 |   200/2983 batches |  lr=20.00  |   0.10 s/batch | loss  9.69 | ppl 16229.42\n",
      "| epoch=  1 |   400/2983 batches |  lr=20.00  |   0.10 s/batch | loss  7.88 | ppl  2651.86\n",
      "| epoch=  1 |   600/2983 batches |  lr=20.00  |   0.10 s/batch | loss  7.09 | ppl  1204.28\n",
      "| epoch=  1 |   800/2983 batches |  lr=20.00  |   0.10 s/batch | loss  6.71 | ppl   823.73\n",
      "| epoch=  1 |  1000/2983 batches |  lr=20.00  |   0.10 s/batch | loss  6.42 | ppl   613.16\n",
      "| epoch=  1 |  1200/2983 batches |  lr=20.00  |   0.10 s/batch | loss  6.25 | ppl   515.73\n",
      "| epoch=  1 |  1400/2983 batches |  lr=20.00  |   0.10 s/batch | loss  6.08 | ppl   437.82\n",
      "| epoch=  1 |  1600/2983 batches |  lr=20.00  |   0.10 s/batch | loss  6.06 | ppl   430.33\n",
      "| epoch=  1 |  1800/2983 batches |  lr=20.00  |   0.10 s/batch | loss  5.84 | ppl   345.25\n",
      "| epoch=  1 |  2000/2983 batches |  lr=20.00  |   0.10 s/batch | loss  5.79 | ppl   328.36\n",
      "| epoch=  1 |  2200/2983 batches |  lr=20.00  |   0.10 s/batch | loss  5.66 | ppl   287.35\n",
      "| epoch=  1 |  2400/2983 batches |  lr=20.00  |   0.10 s/batch | loss  5.66 | ppl   288.36\n",
      "| epoch=  1 |  2600/2983 batches |  lr=20.00  |   0.10 s/batch | loss  5.64 | ppl   281.03\n",
      "| epoch=  1 |  2800/2983 batches |  lr=20.00  |   0.10 s/batch | loss  5.51 | ppl   246.90\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch=  1 | time: 323.19s | val_loss= 5.48 | valid ppl   239.12\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/serialization.py:401: UserWarning: Couldn't retrieve source code for container of type NWPMModel. It won't be checked for correctness upon loading.\n",
      "  warnings.warn(\"Couldn't retrieve source code for container of \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch=  2 |   200/2983 batches |  lr=20.00  |   0.10 s/batch | loss  5.51 | ppl   247.44\n",
      "| epoch=  2 |   400/2983 batches |  lr=20.00  |   0.10 s/batch | loss  5.51 | ppl   246.09\n",
      "| epoch=  2 |   600/2983 batches |  lr=20.00  |   0.10 s/batch | loss  5.30 | ppl   200.96\n",
      "| epoch=  2 |   800/2983 batches |  lr=20.00  |   0.10 s/batch | loss  5.30 | ppl   201.20\n",
      "| epoch=  2 |  1000/2983 batches |  lr=20.00  |   0.10 s/batch | loss  5.26 | ppl   191.74\n",
      "| epoch=  2 |  1200/2983 batches |  lr=20.00  |   0.10 s/batch | loss  5.23 | ppl   186.59\n",
      "| epoch=  2 |  1400/2983 batches |  lr=20.00  |   0.10 s/batch | loss  5.23 | ppl   186.40\n",
      "| epoch=  2 |  1600/2983 batches |  lr=20.00  |   0.10 s/batch | loss  5.29 | ppl   197.66\n",
      "| epoch=  2 |  1800/2983 batches |  lr=20.00  |   0.10 s/batch | loss  5.13 | ppl   169.35\n",
      "| epoch=  2 |  2000/2983 batches |  lr=20.00  |   0.10 s/batch | loss  5.14 | ppl   170.39\n",
      "| epoch=  2 |  2200/2983 batches |  lr=20.00  |   0.10 s/batch | loss  5.02 | ppl   151.18\n",
      "| epoch=  2 |  2400/2983 batches |  lr=20.00  |   0.10 s/batch | loss  5.06 | ppl   156.92\n",
      "| epoch=  2 |  2600/2983 batches |  lr=20.00  |   0.10 s/batch | loss  5.06 | ppl   158.08\n",
      "| epoch=  2 |  2800/2983 batches |  lr=20.00  |   0.10 s/batch | loss  4.98 | ppl   145.82\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch=  2 | time: 322.35s | val_loss= 5.24 | valid ppl   187.73\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch=  3 |   200/2983 batches |  lr=20.00  |   0.10 s/batch | loss  5.03 | ppl   152.66\n",
      "| epoch=  3 |   400/2983 batches |  lr=20.00  |   0.10 s/batch | loss  5.05 | ppl   156.23\n",
      "| epoch=  3 |   600/2983 batches |  lr=20.00  |   0.10 s/batch | loss  4.85 | ppl   127.93\n",
      "| epoch=  3 |   800/2983 batches |  lr=20.00  |   0.10 s/batch | loss  4.90 | ppl   133.85\n",
      "| epoch=  3 |  1000/2983 batches |  lr=20.00  |   0.10 s/batch | loss  4.87 | ppl   130.69\n",
      "| epoch=  3 |  1200/2983 batches |  lr=20.00  |   0.11 s/batch | loss  4.87 | ppl   129.98\n",
      "| epoch=  3 |  1400/2983 batches |  lr=20.00  |   0.10 s/batch | loss  4.89 | ppl   133.56\n",
      "| epoch=  3 |  1600/2983 batches |  lr=20.00  |   0.10 s/batch | loss  4.96 | ppl   143.27\n",
      "| epoch=  3 |  1800/2983 batches |  lr=20.00  |   0.10 s/batch | loss  4.83 | ppl   125.78\n",
      "| epoch=  3 |  2000/2983 batches |  lr=20.00  |   0.10 s/batch | loss  4.86 | ppl   128.95\n"
     ]
    }
   ],
   "source": [
    "train_epochs(ntokens=ntokens, epochs=epochs, n_seq=n_seq, lr=lr, log_interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T21:37:30.691991Z",
     "start_time": "2020-06-24T21:37:30.644761Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the best saved model.\n",
    "with open('model_val_loss_5.085356492710941_val_ppl_161.64.pt', 'rb') as f:\n",
    "    model = torch.load(f)\n",
    "    # after load the rnn params are not a continuous chunk of memory\n",
    "    # this makes them a continuous chunk, and will speed up forward pass\n",
    "    # Currently, only rnn model supports flatten_parameters function.\n",
    "    model.rnn.flatten_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T21:37:32.617560Z",
     "start_time": "2020-06-24T21:37:30.983096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test_loss= 5.01 | test ppl   150.30\n"
     ]
    }
   ],
   "source": [
    "# Run on test data.\n",
    "test_loss = evaluate(test_data)\n",
    "print('=' * 89)\n",
    "print(f'| End of training | {test_loss=:5.2f} | test ppl {math.exp(test_loss):8.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(\n",
    "#     torch.load(\n",
    "#     model_data_filepath + 'word_language_model_quantize.pth',\n",
    "#         map_location = torch.device('cpu')\n",
    "#     )\n",
    "# )\n",
    "# model.eval()\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
